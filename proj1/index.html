<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    body {
      padding: 60px;
      width: 800px;
      margin: auto;
      text-align: left;
      font-weight: 300;
      font-size: small;
      font-family: 'Roboto Mono';
      color: #dfd7d7;
      background-color: #2b303a;
      text-align: justify;
      text-justify: inter-word;
    }

    button {
      background-color: #dfd7d7;
      border: none;
      font-weight: bold;
      text-decoration: none;
      color: #2b303a;
      padding: 5px 10px;
      margin: 2px 2px;
      cursor: pointer;
    }

    h1 {
      font-size: x-large;
    }

    h2 {
      font-size: large;
      color: #d19773;
    }

    h3 {
      font-size: medium;
      color: #d19773;
    }

    h4 {
      font-size: small;
    }

    code {
      font-size: medium;
      display: inline-block;
      background: #171a20;
    }

    a {
      color: #dfd7d7;
    }

    /* width */
    ::-webkit-scrollbar {
      width: 8px;
    }

    /* Track */
    ::-webkit-scrollbar-track {
      background: #dfd7d7;
    }

    /* Handle */
    ::-webkit-scrollbar-thumb {
      background: #2b303a;
    }

    /* Handle on hover */
    ::-webkit-scrollbar-thumb:hover {
      background: #2b303a;
    }
  </style>
  <div align="middle">
    <a href="../proj1/index.html"><button>P1</button></a>
    <a href="../proj2/index.html"><button>P2</button></a>
    <a href="../proj3-1/index.html"><button>P3-1</button></a>
    <a href="../proj3-2/index.html"><button>P3-2</button></a>
    <a href="../proj4/index.html"><button>P4</button></a>
  </div>
  <br>
  <title>CS 184 Rasterizer: Clare Lin, Faywer Liu</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">

  <!-- latex equations -->
  <!-- <link rel="stylesheet" href="https://latex.codecogs.com/css/equation-embed.css" />
  <script src="https://latex.codecogs.com/js/eq_config.js"></script>
  <script src="https://latex.codecogs.com/js/eq_editor-lite-19.js"></script> -->

  <!-- mathjax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<body>

  <h1 align="middle">CS 184: Computer Graphics and Imaging [SP22]</h1>
  <h1 align="middle">Project 1: Rasterizer</h1>
  <h2 align="middle">Clare Lin, Faywer Liu</h2>
  <br><br><img src="images/lion.png" width="800px" class="center">

  <div>

    <br><br>
    <h2 align="middle">Overview</h2>
    <p> This rasterizer is able to take in SVG files and render it in an adjustable UI.
      Features include rasterizing single color triangles, bayecentric interpolated triangles,
      supersampling algorithm for antialiasing, transform functions (translate, scale, and rotate),
      pixel sampling and level sampling with mipmaps for texture mapping.

      <br><br>
      Overall, this was a fun project and we enjoyed learning about rasterization and were surprised by how complex
      it is just to display many triangles on our screens.
    </p>

    <br>
    <h3 align="middle">Task 1: Drawing Single-Color Triangles</h3>

    <p> In the first part of the project. We implemented basic triangle rasterization, which means we want to fill
      triangles in an SVG file with a color. Given the vertices, \((x_{i}, y_{i})\), and color for a triangle, we first
      iterate through each point in a rectangle bounded by the edges of the triangle. Next we use the 3 line test
      written below to determine if the current point is actually inside the triangle before filing in that pixel. For
      \(i\) from 0 to 2,

      $$L_{i} = -(x-x_{i})*\Delta y_{i}+(y-y_{i})*\Delta x_{i}$$

      If the value of \(Li \ge0\) (or \(Li \le 0\) if the order of triangle vertices are given counterclockwise)
      for all three points, then the point is in the line. The x and y indices fed into the equation were incremented by
      0.5 each to get the center of the corresponding pixel for an accurate line test.

      <br><br>Our algorithm is no less worse than one that checks each sample within the bounding box of the triangle
      because it does exactly that. We find the minimum and maximum of each (x, y) value and iterate over that.

    <div align="middle">
      <br><br><img src="images/task1.png" align="middle" width="400px">
      <figcaption align="middle">Rasterized Triangles.</figcaption>
    </div>

    <br>An attempt was made to use OpenMP <code> #pragma omp for </code> commands before for loops to speed up our
    calculations, but the timing results showed no noticeable improvement.
    <p>
      We also brainstormed an idea of speeding up rasterization using a sliding tile method.
      In this method, we would loop from the left until a find a point within the triangle then loop
      from the right until a find a point within the triangle. Then we know that every point between
      these two is inside the triangle and we can skip the arithmetic. This would save us computation roughly
      equal to sampling every point within the triangle.
    </p>
    <br><br>
    <style>
      table.GeneratedTable {
        width: 100%;
        background-color: #ffffff;
        border-collapse: collapse;
        border-width: 2px;
        border-color: #000000;
        border-style: solid;
        color: #000000;
      }

      table.GeneratedTable td,
      table.GeneratedTable th {
        border-width: 2px;
        border-color: #000000;
        border-style: solid;
        padding: 3px;
      }

      table.GeneratedTable thead {
        background-color: #ffc12e;
      }
    </style>

    <!-- HTML Code: Place this code in the document's body (between the 'body' tags) where the table should appear -->
    <table class="GeneratedTable">
      <thead>
        <tr>
          <th>Naive</th>
          <th>"Optimized"</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td>0.268050667</td>
          <td>0.245115</td>
        </tr>
        <tr>
          <td>2.651900667</td>
          <td>2.548970333</td>
        </tr>
      </tbody>
    </table>
  </div>
  <figcaption align="middle">Average values of render times (seconds) of 01_degenerate_square1.svg and
    02_degenerate_square2.svg with 5 trials. </figcaption>

  <div align>
    <br><br>
    <h3 align="middle">Task 2: Antialiasing by Supersampling</h3>

    <p>In the next part of our project, we implemented supersampling on top of our basic triangle rasterization.
      Supersampling is useful for antialiasing in images. Often times we get jaggies and unwanted sharp edges on our
      image. This can be solved by sampling more than we need, then downsampling by averaging to ‘smooth out’ the
      jaggedness. The more samples we take, the less jaggies the end result has.
      <br><br>We made several changes to our rendering pipeline to accommodate supersampling. First, all functions that
      resize the temporary sample buffer had to get a multiplication factor by our sample rate to fit all of our
      samples. In our rasterization function, <code>RasterizerImp::rasterize_triangle()</code>, we nested two more for
      loops to take more samples at each pixel location. Again, to obtain the center of each subpixel, we had to add an
      increment to each point.
    </p>
    <div align="middle">
      <br><br><img src="images/supersample.png" align="middle" width="600px">
      <figcaption align="middle">Brainstorming process for oversampling implementation</figcaption>
    </div>
    <p>
      <br>
      In order to downsample our sample buffer, <code>RasterizerImp::resolve_to_framebuffer()</code> was modified to
      average out every <code>sample_rate</code> number of points into one color, before inserting into the final RGB
      frame buffer array. Our results successfully showed that supersampling decreased the amount of jaggies as the
      sampling rate was increased.
    </p>

    <div align="middle">
      <br><br>
      <table style="width=100%">
        <tbody>
          <tr>
            <td>
              <img src="images/task1.png" align="middle" width="400px">
              <figcaption align="middle">1 Sample Per Pixel</figcaption>
            </td>
            <td>
              <img src="images/task2-4.png" align="middle" width="400px">
              <figcaption align="middle">4 Samples Per Pixel</figcaption>
            </td>
          </tr>

          <tr>
            <td>
              <img src="images/task2-9.png" align="middle" width="400px">
              <figcaption align="middle">9 Samples Per Pixel</figcaption>
            </td>
            <td>
              <img src="images/task2-16.png" align="middle" width="400px">
              <figcaption align="middle">16 Samples Per Pixel</figcaption>
            </td>
          </tr>
        </tbody>
      </table>
    </div>

    <br><br>
    <h3 align="middle">Task 3: Transforms</h3>
    <p>In this section we implemented transforms using the matrices. We are able to translate \(\textbf{T}(t_x,t_y)\),
      rotate \(\textbf{R}(\alpha)\), and scale \(\textbf{S}(s_x,s_y)\) polygons. An application of these transformations
      is manipulating “cubeman” in which we made him dance the naenae. The transformation matrices are listed below.

      $$\textbf{T}(t_x,t_y)=\begin{pmatrix}
      1& 0& t_x\\
      0& 1& t_y\\
      0& 0& 1\\
      \end{pmatrix}$$

      $$\textbf{R}(\alpha)=\begin{pmatrix}
      \cos(\alpha)& -\sin(\alpha)& 0\\
      \sin(\alpha)& \cos(\alpha)& 0\\
      0& 0& 1\\
      \end{pmatrix}$$

      $$\textbf{S}(s_x,s_y)=\begin{pmatrix}
      s_x& 0& 0\\
      0& s_y& 0\\
      0& 0& 1\\
      \end{pmatrix}$$
    </p>
    <div align="middle">
      <br><br> <img src="images/task3.png" align="middle" width="400px">
      <figcaption align="middle">nae nae</figcaption>
    </div>

    <br><br>
    <h3 align="middle">Task 4: Barycentric coordinates</h3>
    <p>Barycentric coordinates are special homogeneous coordinates that can help us get smooth transition values for the
      colors in our triangles when rasterizing. We can linearly interpolate (aka lerp) between each pair of vertices’
      associated color. The image below shows a smooth blended color triangle. The vertices of the triangle are pure
      RGB colors, and as we move away from the vertices, the colors become a blend of the 3 colors with each color
      intensity proportional to the distance away from the vertices. The circle below is also an interpolation across
      color hues and darkness values.
    </p>

    <p>
      We build upon our previous rasterization algorithm by adding the ability to rasterize interpolated color
      triangles. Based on the location in the triangle, we solve for the color ratios: \(\alpha\), \(\beta\), and
      \(\gamma\), before multiplying them with their respective colors to obtain the final color values in the triangle.

      $$V = \alpha V_A + \beta V_B + \gamma V_C$$
    </p>
    <div align="middle">

    </div>

    <div align="middle">
      <br><br>
    </div>

    <div align="middle">
      <table style="width=100%">
        <tbody>
          <tr>
            <td>
              <img src="images/task4-tri.png" align="middle" width="400px">
              <figcaption align="middle">Gradient triangle.</figcaption>
            </td>
            <td>
              <img src="images/task4-circle.png" align="middle" width="400px">
              <figcaption align="middle">Gradient circle.</figcaption>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>



      <br><br>
    <h3 align="middle">Task 5: "Pixel sampling" for texture mapping</h3>
    <p>Pixel sampling is mapping pixels from one image to another (can be differing sizes).</p>
    <p>We implemented pixel sampling for texture mapping by taking the color at the (u, v)
      coordinate in our texture map and mapping it to the (x, y) coordinate in our screen space.
      The two sampling methods we implemented are nearest sampling and bilinear sampling.</p>
    <p>Nearest sampling simply outputs the color of the nearest pixel. This is done by rounding the (u, v) coordinate.
    </p>
    <p>Bilinear sampling takes the 4 nearest sample locations and returns a weighted average color based on location.
      This is
      done through linear interpolation vertically, horizontally, and finally between the previous results.</p>

    <div align="middle">
      <br><br>
      <table style="width=100%">
        <tbody>
          <tr>
            <td>
              <img src="images/task5-near-1.png" align="middle" width="400px">
              <figcaption align="middle">Nearest Sampling, 1 Sample Per Pixel</figcaption>
            </td>
            <td>
              <img src="images/task5-near-16.png" align="middle" width="400px">
              <figcaption align="middle">Nearest Sampling, 16 Samples Per Pixel</figcaption>
            </td>
          </tr>

          <tr>
            <td>
              <img src="images/task5-linear-1.png" align="middle" width="400px">
              <figcaption align="middle">Bilinear Sampling, 1 Sample Per Pixel</figcaption>
            </td>
            <td>
              <img src="images/task5-linear-16.png" align="middle" width="400px">
              <figcaption align="middle">Bilinear Sampling, 16 Samples Per Pixel</figcaption>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
    <p>
      <br>
      We observed some differences between the two sampling methods. Bilinear sampling tends to give a blurrier result
      due to averaging out values, which we can see in the images above. Nearest sampling only clips to the closest
      color for a pixel result, which results in sharper edges in the images, but also more jaggies. In terms of
      computation, bilinear will be more costly. This is especially true when computing images of large dimension for
      bilinear sampling, since we are sampling four times as many locations, and also performing three lerps to obtain a
      weighted average final result.
    </p>
    <p>
      On images with lower resolution, there will be large differences since nearest ignores surrounding pixels with an
      already low sample size.
      On images with larger resolutions, these differences are less noticeable since averages become less useful with
      larger sample sizes.
    </p>

    <br>
    <h3 align="middle">Task 6: "Level sampling" with mipmaps for texture mapping</h3>
    <p>A mipmap is a data structure containing images in which each is a lower resolution (usually ½ the height and
      width) of the previous image. In this application, we store a texture in our mipmap. Level sampling is simply
      sampling from a “level” of a mipmap. As discussed in lecture we can choose a good
      mipmap level with the following formula.

      $$L = max(\sqrt{(\frac {du}{dx})^2 + \frac{dv}{dx})^2}, \sqrt{(\frac {du}{dy})^2 + \frac{dv}{dy})^2})$$
      $$D = \log_2(L)$$

    <p>
      Our implementation allows us to sample from level 0, the nearest level found by the formula, and a
      weighted average of adjacent levels found by the formula.
    </p>

    <br><br>
    <div align="middle">
      <table style="width=100%">
        <tbody>
          <tr>
            <td>
              <img src="images/l0pn.png" align="middle" width="400px">
              <figcaption align="middle">L_ZERO and P_NEAREST</figcaption>
            </td>
            <td>
              <img src="images/l0pl.png" align="middle" width="400px">
              <figcaption align="middle">L_ZERO and P_LINEAR</figcaption>
            </td>
          </tr>

          <tr>
            <td>
              <img src="images/lnpn.png" align="middle" width="400px">
              <figcaption align="middle">L_NEAREST and P_NEAREST</figcaption>
            </td>
            <td>
              <img src="images/lnpl.png" align="middle" width="400px">
              <figcaption align="middle">L_NEAREST and P_LINEAR</figcaption>
            </td>
          </tr>

        </tbody>
      </table>

    </div>
</body>
<br>
<p>
  From our image comparison, we think L_NEAREST and P_LINEAR gives the best results. This is expected as it is almost
  trilinear filtering.
</p>
<p>Supersampling had powerful antialiasing results, but we found that at high sample rates, the images feel too smooth
  and blurred out sometimes. Supersampling uses the most memory and also is the slowest.</p>

<p>Level sampling with a mip map has more subtle antialiasing results. It requires 4/3 times the amount of memory and
  was slower than pixel sampling.</p>

<p>Pixel sampling had great antialiasing results. It requires the least amount of memory and also performed the
  quickest.</p>

<p>We thought that pixel sampling gave the best tradeoffs between antialiasing and memory/speed.</p>

<br><br>
<h3 align="middle">Task 7: Draw something interesting!</h3>
<p>To create this image, we fed a png into <a href=https://www.samcodes.co.uk/project/geometrize-haxe-web/
    target="_blank">Geometrize</a> which converts our png into a svg composed of triangles.
  However,
  the svgparser included in this project only supports colors given in hex while Geometrize outputs colors in the format
  "rgb(r,g,b)" so we had to edit it in <code>svgparser.cpp</code> to allow support for this format.
</p>

<div align="middle">
  <br><br><img src="images/competition.png" align="middle" width="800px">
  <figcaption align="middle">Buff Kirby</figcaption>
</div>

</html>
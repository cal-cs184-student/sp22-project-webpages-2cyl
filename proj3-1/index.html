<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">

<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    :root {
      --bgcolor: #2b2a41;
      --fgcolor: #d7d8df;
      --highlight: #faa0ac;
      font-family: 'Roboto Mono';
      font-weight: 300;
      -webkit-print-color-adjust: exact;
    }

    body {
      padding: 60px;
      width: 800px;
      margin: auto;
      text-align: left;
      font-size: small;
      /* font-family: 'Roboto Mono'; */
      color: var(--fgcolor);
      background-color: var(--bgcolor);
      text-align: justify;
      text-justify: inter-word;

    }

    button {
      background-color: var(--fgcolor);
      border: none;
      font-weight: bold;
      text-decoration: none;
      color: var(--bgcolor);
      padding: 5px 10px;
      margin: 2px 2px;
      cursor: pointer;
    }

    h1 {
      font-size: x-large;
    }

    h2 {
      font-size: large;
      color: var(--highlight);
    }

    h3 {
      font-size: medium;
      color: var(--highlight);
    }

    h4,
    figcaption {
      font-size: small;
    }

    code {
      font-size: medium;
      display: inline-block;
      background: #151420;
    }

    a {
      color: var(--fgcolor);
    }

    /* width */
    ::-webkit-scrollbar {
      width: 8px;
    }

    /* Track */
    ::-webkit-scrollbar-track {
      background: var(--fgcolor);
    }

    /* Handle */
    ::-webkit-scrollbar-thumb {
      background: var(--bgcolor);
    }

    /* Handle on hover */
    ::-webkit-scrollbar-thumb:hover {
      background: var(--bgcolor);
    }
  </style>
  <div align="middle">
    <a href="../proj1/index.html"><button>P1</button></a>
    <a href="../proj2/index.html"><button>P2</button></a>
    <a href="../proj3-1/index.html"><button>P3-1</button></a>
    <a href="../proj3-2/index.html"><button>P3-2</button></a>
    <a href="../proj4/index.html"><button>P4</button></a>
  </div>
  <br>
  <title>CS 184 Path Tracer Part 1: Clare Lin, Faywer Liu</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">

  <!-- mathjax -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>


<body>

  <h1 align="middle">CS 184: Computer Graphics and Imaging [SP22]</h1>
  <h1 align="middle">Project 3-1: Path Tracer</h1>
  <h2 align="middle">Clare Lin, Faywer Liu</h2>
  <br><br><img src="images/task5bunny.png" width="800px" class="center">

  <div>

    <br><br>
    <h2 align="middle">Overview</h2>
    <p> Building a path tracer was fun and challenging. Our path tracer is able to generate rays and perform image to
      camera transformations to display the correct views. We also implemented rendering acceleration algorithms and
      various illumination techniques to quickly render low noise and high quality scenes. We enjoyed learning about the
      various aspects involved in ray tracing.
    </p>

    <p> Unfortunately our schedules conflicted so we split up tasks. This strategy is definately not ideal
      since each part builds upon one another. While this apporach may work in other cases where you
      can abstract away the details, it is much more difficult here. It would probably have been quicker to work
      together on
      each part and we hope to do so in the future.
    </p>

    <br>
    <h3 align="middle">Task 1: Ray Generation and Scene Intersection</h3>

    <p>
      <!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
      Explain the triangle intersection algorithm you implemented in your own words.
      Show images with normal shading for a few small .dae files. -->
      Before we can begin path tracing, we must first generate camera rays. To do this, we transformed
      normalized image coordinates to normalized camera coordinates based on field of view angles along the x and y
      axis (\(hFov\) and \(vFov\)), and a camera-to-world transformation matrix. We make sure to constrain the near and
      far clipping planes as the minimum and maximum render distances for the newly constructed ray.
    </p>
    <p style="color: var(--highlight);">
      $$x_{c} = 2*tan(hFov/2) * (x_{i} - 0.5)$$
      $$y_{c} = 2*tan(vFov/2) * (y_{i} - 0.5)$$
    </p>
    </p>
    <p>
      After ray generation, we need to ray trace the pixel by generating a specified number of random rays within a unit
      grid of the pixel, and obtaining a Monte Carlo estimate of the scene radiance for each pixel.
    </p>
    <p>
      In the next part of the rendering pipeline, ray-triangle intersection and ray-sphere intersection were also
      implemented to determine if our rays have hit any objects in the scene, and to compute the nearest intersection
      point. For ray-triangle intersection, we based our method on the MÃ¶ller-Trumbore intersection algorithm. In this
      method, we do not need to precompute the plane that contains our triangle, increasing efficiency. First, by taking
      the scalar triple product of the two edges, \(E1\) and \(E2\), and the ray direction, \(D\), we find out if the
      ray is parallel to the triangle, and return false when the result is zero. This means that the ray did not hit the
      triangle normal. Next, we compute the \(u\) and \(v\) barycentric coordinates using principles from Cramer's Rule
      and make sure the values are not negative, and their sum is within 1 for a potential valid intersection. Finally,
      we compute the intersection point, \(t\), and make sure it's positive and within our clipping plane bounds. We
      then are also able to compute the intersection normal vector by doing a normalized barycentric interpolation with
      the vertex normals.
    </p>

    <p style="color: var(--highlight);">$$\begin{bmatrix} t\\u\\v\\ \end{bmatrix}
      = \frac{1}{ (D \times E2)\cdot E1}
      \begin{bmatrix}
      (S \times E1)\cdot E2\\
      (D \times E2)\cdot S\\
      (S \times E1)\cdot D\\
      \end{bmatrix}$$

      $$where\:
      E1 = p_2 - p_1, E2 = p_3 - p_1,\:and\: S = o - p_1$$

      $$o + tD = (1-u-v)p_0 + up_1 + vp_2$$</p>
    <p> Ray-sphere intersection was performed with a similar idea that our intersection point should be between our
      clipping plane bounds, but implemented by solving the quadratic formula for two distances, and taking the closer
      as our return intersection point. </p>

    <br>

    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task1-spheres.png" align="middle" width="400px">
            <figcaption align="middle">Spheres with normal shading</figcaption>
          </td>
          <td>
            <img src="images/task1-gems.png" align="middle" width="400px">
            <figcaption align="middle">Gems with normal shading</figcaption>
          </td>
        </tr>
      </tbody>
    </table>


  </div>

  <div align>
    <br><br>
    <h3 align="middle">Task 2: Bounding Volume Hierarchy</h3>

    <!--Walk through your BVH construction algorithm. 
      Explain the heuristic you chose for picking the splitting point.
      Show images with normal shading for a few large 
      .dae files that you can only render with BVH acceleration.
      Compare rendering times on a few scenes with moderately complex geometries
      with and without BVH acceleration. Present your results in a one-paragraph analysis. -->
    <p>
      We now implement a bounding volume hierarchy (BVH) to accelerate our rendering times from \(O(n)\) to
      \(O(log(n))\). Before <code>max_leaf_size</code> is reached, only leaf nodes are created and we simply return our
      basic contructed node. Otherwise, we will create the BVH structure. We pick the most beneficial
      axis to split the bounding box based on the longest extent. This yields higher likelihood that we won't split too
      unevenly. We then pick out splitting point based on the average of the centroids along the axis we chose. The list
      of primitives are then sorted from small to large based on the chosen axis, before we partition the list to only
      contain primitives with centroids that are smaller than our splitting point. We then recursively construct the
      left and right children of the current node. Along the way, we perform checks that we won't be spliting an empty
      node or partition the list such that one side becomes empty.
      Below are results comparing rendering times with and without BVH acceleration.
    </p>

    <br>

    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task2-cow.png" align="middle" width="400px">
            <figcaption align="middle">Cow with normal shading</figcaption>
          </td>
          <td>
            <img src="images/task2-lucy.png" align="middle" width="400px">
            <figcaption align="middle">Lucy with normal shading</figcaption>
          </td>
        </tr>
      </tbody>
    </table>

    <br><br>

    <style>
      table.GeneratedTable {
        width: 100%;
        background-color: var(--fgcolor);
        border-collapse: collapse;
        border-width: 2px;
        border-color: var(--bgcolor);
        border-style: solid;
        font-size: small;
        text-align: center;
        color: var(--bgcolor);
      }

      table.GeneratedTable td,
      table.GeneratedTable th {
        border-width: 2px;
        border-color: var(--bgcolor);
        border-style: solid;
        padding: 3px;
      }

      table.GeneratedTable thead {
        background-color: var(--highlight);
      }
    </style>

    <table class="GeneratedTable">
      <thead>
        <tr>
          <th>Input File</th>
          <th>BVH Accelerated</th>
          <th>Render Time (s)</th>
          <th>Rays per second (million)</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td rowspan="2">cow.dae</td>
          <td>X</td>
          <td>16.8076</td>
          <td>0.0103</td>
        </tr>
        <tr>
          <td>â</td>
          <td>0.0309</td>
          <td>3.9815</td>
        </tr>
        <tr>
          <td rowspan="2">CBlucy.dae<br></td>
          <td>X</td>
          <td>664.1852</td>
          <td>0.0003</td>
        </tr>
        <tr>
          <td>â</td>
          <td>0.0562</td>
          <td>2.5367</td>
        </tr>
      </tbody>
    </table>

    <p>Implementing BVH significantly sped up our renders, especially on larger scenes. Rendering the cow is 544x
      faster than before, and rendering Lucy, a moderately complex scene, is 11818x faster! Unsurprisingly, the average
      number of rays per second traced also skyrocketed. We were surprised by the amount of performance gain from the
      BVH and really appreciate the tree structure now.</p>
  </div>

  <div align>
    <br><br>
    <h3 align="middle">Task 3: Direct Illumination</h3>
    <p>
      We implemented Direct Lighting with uniform hemisphere sampling by approximating the integral
      over all the light arriving in a hemisphere around hit_p. The reflection equation integral can be approximated using the
      following Monte Carlo estimator.
    </p>

    <div align="middle">
      <img src="images/refmc.png" align="middle" width="200px">
      <figcaption align="middle">Monte Carlo Estimator of the Reflection Equation</figcaption>
    </div>

    <p>
      We take num_samples samples of directions in a uniform hemisphere. We then construct
      a ray from hit_p in the sampled direction and test if it intersects a light source. If so, to get the outgoing
      light we use the Monte Carlo Estimator: we multiply the evaluated BSDF with the incoming radiance. We also take into
      account Lambert's cosine
      law and divide by the pdf. We take an average of these outgoing lights by accumulating and dividing by the number
      of samples.
    </p>

    <p>
      To implement importance sampling, we can use the same Monte Carlo Estimator. Instead of sampling uniform
      directions in a hemisphere, we will sample all lights directly. For each light (unless it's the light source), we
      construct sample num_samples directions. For each direction, we construct a ray and if there are no intersections, we proceed
      using the estimator similar to hemisphere sampling above. Again we take an average.
    </p>

    <div align="middle">
      <table style="width:100%">
        <tbody>
          <tr>
            <td>
              <img src="images/task3-bunny-h.png" align="middle" width="400px">
              <figcaption align="middle">Bunny rendered using hemisphere sampling</figcaption>
            </td>
            <td>
              <img src="images/task3-bunny-l.png" align="middle" width="400px">
              <figcaption align="middle">Bunny rendered using light sampling</figcaption>
            </td>
          </tr>

          <tr>
            <td>
              <img src="images/task3-sphere-hemis.png" align="middle" width="400px">
              <figcaption align="middle">Spheres rendered using hemisphere sampling</figcaption>
            </td>
            <td>
              <img src="images/task3-sphere-importance.png" align="middle" width="400px">
              <figcaption align="middle">Spheres rendered using light sampling</figcaption>
            </td>
          </tr>

        </tbody>
      </table>

    </div>

    <br><br>

    <p>
      For the most part, light sampling seems to provide the superior result. Rendering using
      hemisphere sampling results in a generally more noisy image as opposed to light sampling.
      This is most notable as seen in the background walls. The bunny itself is also noisier.
      However the light seems more realistic using hemisphere sampling. The blurring on the side
      is more realistic than the almost perfect shape rendered by light sampling. Though the light may
      look better using hemisphere sampling, due to the overall noise we prefer light sampling.
    </p>

    <br><br>

    <div align="middle">
      <table style="width:100%">
        <tbody>
          <tr>
            <td>
              <img src="images/task3-bunny1.png" align="middle" width="400px">
              <figcaption align="middle">1 sample per pixel and 1 light ray</figcaption>
            </td>
            <td>
              <img src="images/task3-bunny4.png" align="middle" width="400px">
              <figcaption align="middle">1 sample per pixel and 4 light ray</figcaption>
            </td>
          </tr>

          <tr>
            <td>
              <img src="images/task3-bunny16.png" align="middle" width="400px">
              <figcaption align="middle">1 sample per pixel and 16 light ray</figcaption>
            </td>
            <td>
              <img src="images/task3-bunny64.png" align="middle" width="400px">
              <figcaption align="middle">1 sample per pixel and 64 light ray</figcaption>
            </td>
          </tr>

        </tbody>
      </table>

    </div>

    <p>
      When we keep the number of samples per pixels constant at 1, we can see that increasing
      the number of light rays decreases noise.
    </p>
  </div>

  <br><br>
  <h3 align="middle">Task 4: Global Illumination</h3>

  <p> While we have implemented direct illumination where light rays directly hit objects, we haven't
    accounted for indirect illumination where light rays bounce off objects. To implement indirect illumination,
    we need to know the bouncing incoming radiance of an object. However, rays bounce also off other objects and thus need recursion. To prevent infinite recursion, we can
    employ Russian Roulette where there is a chance to terminate the bouncing ray (we used .3 of terminating).
    We can also terminate if we bounce max_ray_depth times. Then if we don't terminate, we construct a ray using a
    sampled direction.
    If we have an intersection, we use the reflection equation once again where the incoming radiance is a recursive
    call.
  </p>

  <p>
    Below are examples of global illumination.
  </p>

  <div align="middle">
    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task4-bunny.png" align="middle" width="400px">
            <figcaption align="middle">Bunny rendered with global illumination</figcaption>
          </td>
          <td>
            <img src="images/task4-dragon.png" align="middle" width="400px">
            <figcaption align="middle">Dragon rendered with global illumination</figcaption>
          </td>
        </tr>
      </tbody>
    </table>
    <br><br>
  </div>

  <p>
    Below is direct and indirect illumination.
  </p>

  <div align="middle">
    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task4-bunny-direct.png" align="middle" width="400px">
            <figcaption align="middle">Bunny rendered with only direct illumination</figcaption>
          </td>
          <td>
            <img src="images/task4-bunny-indirect.png" align="middle" width="400px">
            <figcaption align="middle">Dragon rendered with only indirect illumination</figcaption>
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <br><br>

  <p>
    Below we experiment with differing max_ray_depth values.
  </p>

  <div align="middle">
    <img src="images/task4-bunny-m0.png" align="middle" width="400px">
    <figcaption align="middle">Bunny rendered with max_ray_depth = 0</figcaption>
  </div>

  <div align="middle">
    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task4-bunny-m1.png" align="middle" width="400px">
            <figcaption align="middle">Bunny rendered with max_ray_depth = 1</figcaption>
          </td>

          <td>
            <img src="images/task4-bunny-m2.png" align="middle" width="400px">
            <figcaption align="middle">Bunny rendered with max_ray_depth = 2</figcaption>
          </td>
        <tr>
          <td>
            <img src="images/task4-bunny-m3.png" align="middle" width="400px">
            <figcaption align="middle">Bunny rendered with max_ray_depth = 3</figcaption>
          </td>

          <td>
            <img src="images/task4-bunny-m100.png" align="middle" width="400px">
            <figcaption align="middle">Bunny rendered with max_ray_depth = 100</figcaption>
          </td>
        </tr>

      </tbody>
    </table>

  </div>
  <br><br>
  <p>
    When max_ray_depth = 0, we return a Vector3D(0, 0, 0). This can be seen as we only render
    the zero bounce illumination. When max_ray_depth = 1, we basically have only direct illumination.
    When max_ray_depth >= 2, we can see that the ceiling gets rendered. Everything else also gets
    brighter. As max_ray_depth > 2 increases, we notice things get brighter but the differences become less
    noticable.
  </p>
  <br><br>

  <div align="middle">
    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task4-bunny1.png" align="middle" width="400px">
            <figcaption align="middle">Sample-per-pixel rate = 1 and 4 light rays</figcaption>
          </td>
          <td>
            <img src="images/task4-bunny2.png" align="middle" width="400px">
            <figcaption align="middle">Sample-per-pixel rate = 2 and 4 light rays</figcaption>
          </td>
        </tr>

        <tr>
          <td>
            <img src="images/task4-bunny4.png" align="middle" width="400px">
            <figcaption align="middle">Sample-per-pixel rate = 4 and 4 light rays</figcaption>
          </td>
          <td>
            <img src="images/task4-bunny8.png" align="middle" width="400px">
            <figcaption align="middle">Sample-per-pixel rate = 8 and 4 light rays</figcaption>
          </td>
        </tr>
        <tr>
          <td>
            <img src="images/task4-bunny16.png" align="middle" width="400px">
            <figcaption align="middle">Sample-per-pixel rate = 16 and 4 light rays</figcaption>
          </td>
          <td>
            <img src="images/task4-bunny64.png" align="middle" width="400px">
            <figcaption align="middle">Sample-per-pixel rate = 64 and 4 light rays</figcaption>
          </td>
        </tr>

      </tbody>
    </table>

    <div align="middle">
      <img src="images/task4-bunny1024.png" align="middle" width="400px">
      <figcaption align="middle">Sample-per-pixel rate = 1024 and 4 light rays</figcaption>
    </div>

  </div>

  <br><br>
  <h3 align="middle">Task 5: Adaptive Sampling</h3>
  <p> We implemented adaptive sampling in order to more efficiently render our images. If a pixel converges quickly, we
    stop sampling, and obtain our radiance average for that pixel by diving the total
    radiance by the number of samples seen so far. If a pixel is slow to converge, we carry out the maximum number of
    random samples, when applicable. Adaptive sampling becomes more efficient when many pixels converge quickly, and
    do not require the full number of samples to accuratly represent the final color.
  </p>
  <p> The convergence criteria is based on the mean, \(\mu\), the standard deviation, \(\sigma\), and the number of
    samples taken so far, \(n\). The following equations decribe the convergence criteria, with \(s1\) and \(s2\) being
    the sum of illuminance so far and the sum of squares of illuminance so far, respectively. The magic number 1.96
    comes from solving for a confidence interval of 95% that we are in our pixel's desired illuminance based on the
    \(n\) pixels so far.
  </p>

  <p style="color: var(--highlight);">
    $$ 1.96 \times \frac{\sigma}{\sqrt{n}} \leq maxTolerance \cdot \mu$$
    $$where\:
    \: \mu=\frac{s_1}{n},
    ââ\: \sigma=\sqrt{\frac{1}{n-1}\cdot\left(s_2-\frac{s_1^2}{n}\right)}
    $$
  </p>

  <p>The results of rendering the bunny scene with 2048 sampls per pixel and adaptive sampling yields
    crisp results with a fast rendering time. The sample rate image confirms that we have sampled varing amounts for
    each pixel throughout the image, with blue areas representing low sampling rates, green areas representing medium
    sampling rates, and red areas representing high sampling rates.
  </p>

  <br>

  <div align="middle">
    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task5bunny.png" align="middle" width="400px">
            <figcaption align="middle">Noise Free Bunny</figcaption>
          </td>
          <td>
            <img src="images/task5bunny_rate.png" align="middle" width="400px">
            <figcaption align="middle">Sample Rate of Bunny</figcaption>
          </td>
        </tr>
      </tbody>
    </table>
  </div>

  <div align="middle">
    <table style="width:100%">
      <tbody>
        <tr>
          <td>
            <img src="images/task5-bench.png" align="middle" width="400px">
            <figcaption align="middle">Noise Free Bench</figcaption>
          </td>
          <td>
            <img src="images/task5-bench-rate.png" align="middle" width="400px">
            <figcaption align="middle">Sample Rate of Bench</figcaption>
          </td>
        </tr>
      </tbody>
    </table>
  </div>





</body>

</html>